{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"authorship_tag":"ABX9TyOJcejHbno+NrZBWw1uNEOQ"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6166880,"sourceType":"datasetVersion","datasetId":908655},{"sourceId":348950,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":291358,"modelId":312029}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing the header files\n!pip install pinecone sentence-transformers transformers rank_bm25 gradio pypdf nltk rouge_score deepeval","metadata":{"id":"e2h3Vh1pB1WV","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:48:08.675932Z","iopub.execute_input":"2025-04-21T04:48:08.676166Z","iopub.status.idle":"2025-04-21T04:50:42.440827Z","shell.execute_reply.started":"2025-04-21T04:48:08.676144Z","shell.execute_reply":"2025-04-21T04:50:42.439810Z"}},"outputs":[{"name":"stdout","text":"Collecting pinecone\n  Downloading pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nCollecting rank_bm25\n  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting gradio\n  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting deepeval\n  Downloading deepeval-2.7.5-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.1.31)\nCollecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.9.0.post0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.13.1)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.3.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.8.0 (from gradio)\n  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio)\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (14.2)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from deepeval) (3.11.16)\nCollecting anthropic<0.50.0,>=0.49.0 (from deepeval)\n  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\nCollecting black (from deepeval)\n  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: coverage in /usr/local/lib/python3.11/dist-packages (from deepeval) (7.8.0)\nCollecting google-genai<2.0.0,>=1.9.0 (from deepeval)\n  Downloading google_genai-1.11.0-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: grpcio<2.0.0,>=1.67.1 in /usr/local/lib/python3.11/dist-packages (from deepeval) (1.70.0)\nCollecting instructor (from deepeval)\n  Downloading instructor-1.7.9-py3-none-any.whl.metadata (22 kB)\nCollecting langchain_community (from deepeval)\n  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain_openai (from deepeval)\n  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\nCollecting llama-index (from deepeval)\n  Downloading llama_index-0.12.31-py3-none-any.whl.metadata (12 kB)\nCollecting ollama (from deepeval)\n  Downloading ollama-0.4.8-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from deepeval) (1.61.1)\nCollecting opentelemetry-api<2.0.0,>=1.24.0 (from deepeval)\n  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 (from deepeval)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting opentelemetry-sdk<2.0.0,>=1.24.0 (from deepeval)\n  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting portalocker (from deepeval)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nCollecting posthog<4.0.0,>=3.23.0 (from deepeval)\n  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from deepeval) (8.3.4)\nCollecting pytest-asyncio (from deepeval)\n  Downloading pytest_asyncio-0.26.0-py3-none-any.whl.metadata (4.0 kB)\nCollecting pytest-repeat (from deepeval)\n  Downloading pytest_repeat-0.9.4-py3-none-any.whl.metadata (4.9 kB)\nCollecting pytest-rerunfailures<13.0,>=12.0 (from deepeval)\n  Downloading pytest_rerunfailures-12.0-py3-none-any.whl.metadata (18 kB)\nCollecting pytest-xdist (from deepeval)\n  Downloading pytest_xdist-3.6.1-py3-none-any.whl.metadata (4.3 kB)\nCollecting rich<14.0.0,>=13.6.0 (from deepeval)\n  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: sentry-sdk in /usr/local/lib/python3.11/dist-packages (from deepeval) (2.21.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from deepeval) (75.1.0)\nRequirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.9.0)\nRequirement already satisfied: tenacity<=9.0.0 in /usr/local/lib/python3.11/dist-packages (from deepeval) (9.0.0)\nCollecting twine==5.1.1 (from deepeval)\n  Downloading twine-5.1.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from deepeval) (0.45.1)\nCollecting pkginfo>=1.8.1 (from twine==5.1.1->deepeval)\n  Downloading pkginfo-1.12.1.2-py3-none-any.whl.metadata (13 kB)\nCollecting readme-renderer>=35.0 (from twine==5.1.1->deepeval)\n  Downloading readme_renderer-44.0-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from twine==5.1.1->deepeval) (1.0.0)\nRequirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.11/dist-packages (from twine==5.1.1->deepeval) (8.6.1)\nRequirement already satisfied: keyring>=15.1 in /usr/lib/python3/dist-packages (from twine==5.1.1->deepeval) (23.5.0)\nCollecting rfc3986>=1.4.0 (from twine==5.1.1->deepeval)\n  Downloading rfc3986-2.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\nCollecting pkginfo>=1.8.1 (from twine==5.1.1->deepeval)\n  Downloading pkginfo-1.10.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.50.0,>=0.49.0->deepeval) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<0.50.0,>=0.49.0->deepeval) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<0.50.0,>=0.49.0->deepeval) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nCollecting anyio<5.0,>=3.0 (from gradio)\n  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.9.0->deepeval) (2.27.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.2.18)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.67.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.32.1->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval)\n  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval)\n  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nCollecting monotonic>=1.5 (from posthog<4.0.0,>=3.23.0->deepeval)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nCollecting backoff>=1.10.0 (from posthog<4.0.0,>=3.23.0->deepeval)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\nRequirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->deepeval) (2.0.0)\nRequirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->deepeval) (1.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.6.0->deepeval) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.6.0->deepeval) (2.19.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->deepeval) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->deepeval) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->deepeval) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->deepeval) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->deepeval) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->deepeval) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->deepeval) (1.19.0)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black->deepeval) (1.0.0)\nCollecting pathspec>=0.9.0 (from black->deepeval)\n  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->deepeval) (4.3.7)\nRequirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor->deepeval) (0.16)\nCollecting langchain-core<1.0.0,>=0.3.51 (from langchain_community->deepeval)\n  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain<1.0.0,>=0.3.23 (from langchain_community->deepeval)\n  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community->deepeval) (2.0.38)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community->deepeval) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community->deepeval)\n  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community->deepeval) (0.3.8)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community->deepeval)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting openai (from deepeval)\n  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai->deepeval) (0.9.0)\nCollecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index->deepeval)\n  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\nCollecting llama-index-cli<0.5.0,>=0.4.1 (from llama-index->deepeval)\n  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting llama-index-core<0.13.0,>=0.12.31 (from llama-index->deepeval)\n  Downloading llama_index_core-0.12.31-py3-none-any.whl.metadata (2.6 kB)\nCollecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\nCollecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->deepeval)\n  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\nCollecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n  Downloading llama_index_llms_openai-0.3.37-py3-none-any.whl.metadata (3.3 kB)\nCollecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index->deepeval)\n  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\nCollecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\nCollecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index->deepeval)\n  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\nCollecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index->deepeval)\n  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\nCollecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->deepeval)\n  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\nCollecting execnet>=2.1 (from pytest-xdist->deepeval)\n  Downloading execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->deepeval) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community->deepeval) (0.9.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (1.17.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (4.9)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=3.6->twine==5.1.1->deepeval) (3.21.0)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain_community->deepeval)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community->deepeval) (1.33)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community->deepeval) (0.23.0)\nCollecting banks<3.0.0,>=2.0.0 (from llama-index-core<0.13.0,>=0.12.31->llama-index->deepeval)\n  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\nCollecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.31->llama-index->deepeval)\n  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\nCollecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.31->llama-index->deepeval)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.31->llama-index->deepeval) (1.6.0)\nCollecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->deepeval)\n  Downloading llama_cloud-0.1.18-py3-none-any.whl.metadata (902 bytes)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (4.13.3)\nCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval)\n  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\nCollecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval)\n  Downloading llama_parse-0.6.12-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->deepeval) (0.1.2)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community->deepeval)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nCollecting nh3>=0.2.14 (from readme-renderer>=35.0->twine==5.1.1->deepeval)\n  Downloading nh3-0.2.21-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\nRequirement already satisfied: docutils>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from readme-renderer>=35.0->twine==5.1.1->deepeval) (0.21.2)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community->deepeval) (3.1.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nCollecting griffe (from banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.31->llama-index->deepeval)\n  Downloading griffe-1.7.2-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->deepeval) (2.6)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community->deepeval) (3.0.0)\nCollecting llama-cloud-services>=0.6.12 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->deepeval)\n  Downloading llama_cloud_services-0.6.12-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval) (0.6.1)\nRequirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3.0.0,>=2.0.0->llama-index-core<0.13.0,>=0.12.31->llama-index->deepeval) (0.4.6)\nDownloading pinecone-6.0.2-py3-none-any.whl (421 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nDownloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading deepeval-2.7.5-py3-none-any.whl (590 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.2/590.2 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading twine-5.1.1-py3-none-any.whl (38 kB)\nDownloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_genai-1.11.0-py3-none-any.whl (159 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.7/159.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading anyio-4.9.0-py3-none-any.whl (100 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\nDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\nDownloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytest_rerunfailures-12.0-py3-none-any.whl (12 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nDownloading instructor-1.7.9-py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai-1.75.0-py3-none-any.whl (646 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index-0.12.31-py3-none-any.whl (7.0 kB)\nDownloading ollama-0.4.8-py3-none-any.whl (13 kB)\nDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nDownloading pytest_asyncio-0.26.0-py3-none-any.whl (19 kB)\nDownloading pytest_repeat-0.9.4-py3-none-any.whl (4.2 kB)\nDownloading pytest_xdist-3.6.1-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading execnet-2.1.1-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\nDownloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\nDownloading llama_index_core-0.12.31-py3-none-any.whl (808 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.7/808.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\nDownloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\nDownloading llama_index_llms_openai-0.3.37-py3-none-any.whl (23 kB)\nDownloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\nDownloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\nDownloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\nDownloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m39.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\nDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\nDownloading pkginfo-1.10.0-py3-none-any.whl (30 kB)\nDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m46.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading readme_renderer-44.0-py3-none-any.whl (13 kB)\nDownloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\nDownloading banks-2.1.2-py3-none-any.whl (28 kB)\nDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\nDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading llama_cloud-0.1.18-py3-none-any.whl (253 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_parse-0.6.12-py3-none-any.whl (4.9 kB)\nDownloading nh3-0.2.21-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.0/739.0 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\nDownloading llama_cloud_services-0.6.12-py3-none-any.whl (36 kB)\nDownloading griffe-1.7.2-py3-none-any.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=a326b837f7a4caf8f0c019e074fa6dcf1b5aa2ec928c05eeb97c8e2ae48f8e10\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: striprtf, monotonic, filetype, dirtyjson, uvicorn, tomlkit, semantic-version, ruff, rfc3986, python-multipart, python-dotenv, protobuf, portalocker, pkginfo, pinecone-plugin-interface, pathspec, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nh3, httpx-sse, groovy, griffe, ffmpy, execnet, backoff, anyio, starlette, rich, readme-renderer, pytest-xdist, pytest-rerunfailures, pytest-repeat, pytest-asyncio, posthog, pinecone, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, black, twine, safehttpx, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, openai, ollama, nvidia-cusolver-cu12, llama-cloud, gradio-client, google-genai, fastapi, banks, anthropic, opentelemetry-sdk, langchain-core, instructor, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain_openai, langchain, llama-index-core, llama-index-llms-openai, llama-index-agent-openai, llama-cloud-services, llama-parse, llama-index-program-openai, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-readers-file, llama-index-question-gen-openai, llama-index-multi-modal-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-cli, llama-index, langchain_community, rouge_score, rank_bm25, gradio, deepeval\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: anyio\n    Found existing installation: anyio 3.7.1\n    Uninstalling anyio-3.7.1:\n      Successfully uninstalled anyio-3.7.1\n  Attempting uninstall: rich\n    Found existing installation: rich 14.0.0\n    Uninstalling rich-14.0.0:\n      Successfully uninstalled rich-14.0.0\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.16.0\n    Uninstalling opentelemetry-api-1.16.0:\n      Successfully uninstalled opentelemetry-api-1.16.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n  Attempting uninstall: openai\n    Found existing installation: openai 1.61.1\n    Uninstalling openai-1.61.1:\n      Successfully uninstalled openai-1.61.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: google-genai\n    Found existing installation: google-genai 0.8.0\n    Uninstalling google-genai-0.8.0:\n      Successfully uninstalled google-genai-0.8.0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.16.0\n    Uninstalling opentelemetry-sdk-1.16.0:\n      Successfully uninstalled opentelemetry-sdk-1.16.0\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.35\n    Uninstalling langchain-core-0.3.35:\n      Successfully uninstalled langchain-core-0.3.35\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.6\n    Uninstalling langchain-text-splitters-0.3.6:\n      Successfully uninstalled langchain-text-splitters-0.3.6\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.18\n    Uninstalling langchain-0.3.18:\n      Successfully uninstalled langchain-0.3.18\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed anthropic-0.49.0 anyio-4.9.0 backoff-2.2.1 banks-2.1.2 black-25.1.0 deepeval-2.7.5 dirtyjson-1.0.8 execnet-2.1.1 fastapi-0.115.12 ffmpy-0.5.0 filetype-1.2.0 google-genai-1.11.0 gradio-5.25.2 gradio-client-1.8.0 griffe-1.7.2 groovy-0.1.2 httpx-sse-0.4.0 instructor-1.7.9 langchain-0.3.23 langchain-core-0.3.54 langchain-text-splitters-0.3.8 langchain_community-0.3.21 langchain_openai-0.3.14 llama-cloud-0.1.18 llama-cloud-services-0.6.12 llama-index-0.12.31 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.1 llama-index-core-0.12.31 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.37 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.12 monotonic-1.6 nh3-0.2.21 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ollama-0.4.8 openai-1.75.0 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 pathspec-0.12.1 pinecone-6.0.2 pinecone-plugin-interface-0.0.7 pkginfo-1.10.0 portalocker-3.1.1 posthog-3.25.0 protobuf-5.29.4 pydantic-settings-2.9.1 pytest-asyncio-0.26.0 pytest-repeat-0.9.4 pytest-rerunfailures-12.0 pytest-xdist-3.6.1 python-dotenv-1.1.0 python-multipart-0.0.20 rank_bm25-0.2.2 readme-renderer-44.0 rfc3986-2.0.0 rich-13.9.4 rouge_score-0.1.2 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 striprtf-0.0.26 tomlkit-0.13.2 twine-5.1.1 uvicorn-0.34.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# for the langchain and the google\n%pip install -qU langgraph==0.2.45 langchain-google-genai==2.0.4\n%pip install -qU google-api-core protobuf tensorflow==2.17.0","metadata":{"id":"nBqNYp9sCD19","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:53:42.582882Z","iopub.execute_input":"2025-04-21T04:53:42.583650Z","iopub.status.idle":"2025-04-21T04:55:09.453089Z","shell.execute_reply.started":"2025-04-21T04:53:42.583610Z","shell.execute_reply":"2025-04-21T04:55:09.452067Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nopentelemetry-proto 1.32.1 requires protobuf<6.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\ntensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nopentelemetry-proto 1.32.1 requires protobuf<6.0,>=5.0, but you have protobuf 4.25.6 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.24.2 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.17.0 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.2 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.17.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# for the pinecone\n! pip install langchain-pinecone\n","metadata":{"id":"ZWk90aqhCQdp","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:56:08.049397Z","iopub.execute_input":"2025-04-21T04:56:08.050270Z","iopub.status.idle":"2025-04-21T04:56:14.198564Z","shell.execute_reply.started":"2025-04-21T04:56:08.050240Z","shell.execute_reply":"2025-04-21T04:56:14.197670Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain-pinecone\n  Downloading langchain_pinecone-0.2.5-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-pinecone) (0.3.54)\nRequirement already satisfied: pinecone<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (6.0.2)\nCollecting aiohttp<3.11,>=3.10 (from langchain-pinecone)\n  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\nRequirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-pinecone) (1.26.4)\nCollecting langchain-tests<1.0.0,>=0.3.7 (from langchain-pinecone)\n  Downloading langchain_tests-0.3.19-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (6.2.0)\nRequirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.19.0)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.3.8)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (9.0.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.33)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (6.0.2)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (4.13.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.11.3)\nRequirement already satisfied: pytest<9,>=7 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (8.3.4)\nRequirement already satisfied: pytest-asyncio<1,>=0.20 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.26.0)\nRequirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.28.1)\nCollecting syrupy<5,>=4 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n  Downloading syrupy-4.9.1-py3-none-any.whl.metadata (38 kB)\nCollecting pytest-socket<1,>=0.6.0 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n  Downloading pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->langchain-pinecone) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->langchain-pinecone) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->langchain-pinecone) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->langchain-pinecone) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->langchain-pinecone) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->langchain-pinecone) (2.4.1)\nRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2025.1.31)\nRequirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (0.0.7)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2.9.0.post0)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2.3.0)\n\u001b[33mWARNING: pinecone 6.0.2 does not provide the extra 'async'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.10.15)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.32.3)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.4.0)\nRequirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.0.0)\nRequirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.5.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (1.17.0)\nRequirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain-pinecone) (0.3.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->langchain-pinecone) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->langchain-pinecone) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.4->langchain-pinecone) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.4->langchain-pinecone) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.4->langchain-pinecone) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.4.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.3.1)\nDownloading langchain_pinecone-0.2.5-py3-none-any.whl (16 kB)\nDownloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_tests-0.3.19-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\nDownloading syrupy-4.9.1-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: syrupy, pytest-socket, aiohttp, langchain-tests, langchain-pinecone\n  Attempting uninstall: aiohttp\n    Found existing installation: aiohttp 3.11.16\n    Uninstalling aiohttp-3.11.16:\n      Successfully uninstalled aiohttp-3.11.16\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed aiohttp-3.10.11 langchain-pinecone-0.2.5 langchain-tests-0.3.19 pytest-socket-0.7.0 syrupy-4.9.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# importing the pinecone required things\nfrom langchain_pinecone import Pinecone\nfrom langchain_community.vectorstores import Pinecone\nimport os\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\n\nfrom pinecone import Pinecone\nimport kagglehub\n\nfrom rank_bm25 import BM25Okapi\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nimport torch\nimport spacy\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport pandas as pd\n\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom rouge_score import rouge_scorer\nfrom deepeval.metrics import GEval, ContextualRelevancyMetric, SummarizationMetric, PromptAlignmentMetric\n\nimport re\n# Example usage\nfrom io import BytesIO\nimport pypdf","metadata":{"id":"_1t0F-slCaHe","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:57:10.048628Z","iopub.execute_input":"2025-04-21T04:57:10.049282Z","iopub.status.idle":"2025-04-21T04:57:47.445554Z","shell.execute_reply.started":"2025-04-21T04:57:10.049254Z","shell.execute_reply":"2025-04-21T04:57:47.444894Z"}},"outputs":[{"name":"stderr","text":"2025-04-21 04:57:27.649843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-21 04:57:27.670053: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-04-21 04:57:27.675338: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Download necessary NLTK data\nnltk.download('punkt_tab')\nnltk.download('averaged_perceptron_tagger_eng')","metadata":{"id":"C7T9N8dmDVA7","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:59:04.945984Z","iopub.execute_input":"2025-04-21T04:59:04.947144Z","iopub.status.idle":"2025-04-21T04:59:05.255361Z","shell.execute_reply.started":"2025-04-21T04:59:04.947115Z","shell.execute_reply":"2025-04-21T04:59:05.254743Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# pine cone initialization\n\nfrom pinecone import Pinecone, ServerlessSpec\n\npc = Pinecone(api_key=\"pcsk_4qe8ki_SXT2QJ4NGUsqJv69m5k8ELcJPS9c71jkshzEFd5AQqM3Q5F6MDEehhwJEScD4oq\")","metadata":{"id":"N9-S0W67CjUi","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:59:07.953491Z","iopub.execute_input":"2025-04-21T04:59:07.954067Z","iopub.status.idle":"2025-04-21T04:59:07.960216Z","shell.execute_reply.started":"2025-04-21T04:59:07.954038Z","shell.execute_reply":"2025-04-21T04:59:07.959333Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# connect to pine cone and getting status.\n\nindex_name = \"legal2-contract-search-index\"\n# Connect to the index\nindex = pc.Index(index_name)\nprint(index.describe_index_stats())","metadata":{"id":"5noP_fCDCubw","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:59:12.926450Z","iopub.execute_input":"2025-04-21T04:59:12.927208Z","iopub.status.idle":"2025-04-21T04:59:14.135044Z","shell.execute_reply.started":"2025-04-21T04:59:12.927183Z","shell.execute_reply":"2025-04-21T04:59:14.134391Z"}},"outputs":[{"name":"stdout","text":"{'dimension': 384,\n 'index_fullness': 0.0,\n 'metric': 'cosine',\n 'namespaces': {'': {'vector_count': 510}},\n 'total_vector_count': 510,\n 'vector_type': 'dense'}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# for the database things\n# Set up Pinecone credentials\npc = Pinecone(api_key=\"pcsk_4qe8ki_SXT2QJ4NGUsqJv69m5k8ELcJPS9c71jkshzEFd5AQqM3Q5F6MDEehhwJEScD4oq\")\n#pc = Pinecone(api_key=\"pcsk_5mdDMR_HB4yT8PAsi5THNDFUZrpoiRHm68NKU6CmLaNj4AqmN46MtdSZM3h8TanPGVnZtk\")\n\n# Set up Kaggle credentials\nos.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content\"\n\n# Download the CUAD dataset\nCUAD_FOLDER = kagglehub.dataset_download(\"konradb/atticus-open-contract-dataset-aok-beta\")\nCUAD_FOLDER = os.path.join(CUAD_FOLDER, \"CUAD_v1\", \"full_contract_txt\")","metadata":{"id":"lv0SbOytC3DI","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:59:18.762037Z","iopub.execute_input":"2025-04-21T04:59:18.762308Z","iopub.status.idle":"2025-04-21T04:59:18.914560Z","shell.execute_reply.started":"2025-04-21T04:59:18.762284Z","shell.execute_reply":"2025-04-21T04:59:18.914039Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# function to load the contract\n# Function to load contract text files\ndef load_contracts(folder_path):\n    contracts = {}\n    try:\n        for filename in os.listdir(folder_path):\n            if filename.endswith(\".txt\"):\n                with open(os.path.join(folder_path, filename), \"r\", encoding=\"utf-8\") as file:\n                    contracts[filename] = file.read()\n        print(f\"Loaded {len(contracts)} contracts for processing.\")\n    except Exception as e:\n        print(f\"Error loading contracts: {e}\")\n    return contracts\n\n# Load contracts\ncontracts = load_contracts(CUAD_FOLDER)","metadata":{"id":"D6Npxx3IDeke","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:59:25.558311Z","iopub.execute_input":"2025-04-21T04:59:25.558955Z","iopub.status.idle":"2025-04-21T04:59:30.639577Z","shell.execute_reply.started":"2025-04-21T04:59:25.558930Z","shell.execute_reply":"2025-04-21T04:59:30.638725Z"}},"outputs":[{"name":"stdout","text":"Loaded 510 contracts for processing.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# function to generate the embeddings\n# Initialize embedding model\nembedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n#embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n\n# Load Spacy for POS tagging\ntry:\n    nlp = spacy.load(\"en_core_web_sm\")\n    print(\"Spacy model loaded successfully\")\nexcept:\n    # If model not found, download it\n    print(\"Downloading Spacy model...\")\n    spacy.cli.download(\"en_core_web_sm\")\n    nlp = spacy.load(\"en_core_web_sm\")\n    print(\"Spacy model loaded successfully after download\")","metadata":{"id":"csl-4GAJDqxR","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:59:34.767077Z","iopub.execute_input":"2025-04-21T04:59:34.767704Z","iopub.status.idle":"2025-04-21T04:59:41.897636Z","shell.execute_reply.started":"2025-04-21T04:59:34.767677Z","shell.execute_reply":"2025-04-21T04:59:41.896727Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0d58a9be6d243e9bb901d874b8743db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae9df89cff24b819ff7ee07217143fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3c26f2525364055ade9c3bd3a357ad0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22dc8bce8404414fbfd3b38c81a212de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9b625e22e349c8af820bba1d5a443a"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b66af542dc2f44fba4f610b6385d7fc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e85198c119624f85b940acc00e42f425"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d206bd09d18d4a0baa2d15cb7943fc6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fff1216a285e4c19988a6432c793a2da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43acd95f279643729dec52884764ae0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39132e51fc97497681b197dacac38d7c"}},"metadata":{}},{"name":"stdout","text":"Spacy model loaded successfully\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# the variable with the index as the file name and the values as the contract text.\ncontract_text = dict(zip(contract_filenames, contract_texts))\n\n# the variable with the index as the file name and the values as the embeddings\ncontract_emb = dict(zip(contract_filenames, contract_embeddings))\n","metadata":{"id":"uI7wYm1aD2Zu","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:00:55.398112Z","iopub.execute_input":"2025-04-21T05:00:55.398431Z","iopub.status.idle":"2025-04-21T05:00:55.402937Z","shell.execute_reply.started":"2025-04-21T05:00:55.398384Z","shell.execute_reply":"2025-04-21T05:00:55.402254Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# generating the embeddings\ndef compute_embeddings(texts, batch_size=32):\n    embeddings = []\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i+batch_size]\n        embeddings.append(embedding_model.encode(batch, convert_to_numpy=True))\n    return np.vstack(embeddings)\n\n# Compute embeddings for contracts\ncontract_filenames = list(contracts.keys())\ncontract_texts = list(contracts.values())\ncontract_embeddings = compute_embeddings(contract_texts)","metadata":{"id":"5Fzbfm9vEC3X","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:00:22.488987Z","iopub.execute_input":"2025-04-21T05:00:22.489849Z","iopub.status.idle":"2025-04-21T05:00:34.651280Z","shell.execute_reply.started":"2025-04-21T05:00:22.489817Z","shell.execute_reply":"2025-04-21T05:00:34.650444Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e46e8a14a92419d81e806cc61090d8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f88552e83ba45d0878b24d3f6d6a619"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e4a8a54085241749af7ebe2388da5b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54db1377ed934dbaa5e0d542bb320ac2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54903834827f4a45945d12e17e64db17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2548879426341ddaee9607774a311da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1474375f038f4ecea8bdd0d32af3deee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86a975073b3c4fe5923b6afdfe54a866"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"643d469ebc994b8687b4b4c2e3994d8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b7598db6fe248d2bb5db8cb468a5b35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7a49757db904b888fef7e044e134609"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"887401d123f04e2ca0c3a8cd7896755b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c6b72fb854c4ddaa0903cfb77426a28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d6bd97f603d4809acaf4fb94749577f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecaa276d58de409e9b8154e3bf8f8ae4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bf85d4b3576462da07c96dfb568ca70"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# function for storing the embeddings in .csv file\nimport csv\n\nprint(f\"Embeddings shape: {contract_embeddings.shape}\")\n\n# Create DataFrame with filenames\nembedding_df = pd.DataFrame({\n    'filename': contract_filenames\n})\n\n# Add embedding columns (one column per dimension)\nembedding_dims = contract_embeddings.shape[1]\nfor i in range(embedding_dims):\n    embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n\n# Save to CSV\ncsv_path = '/kaggle/working/contract_embeddings.csv'\nembedding_df.to_csv(csv_path, index=False)\nprint(f\"Embeddings saved to {csv_path}\")","metadata":{"id":"tz5Tl95rEH7F","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:01:02.247905Z","iopub.execute_input":"2025-04-21T05:01:02.248563Z","iopub.status.idle":"2025-04-21T05:01:02.666767Z","shell.execute_reply.started":"2025-04-21T05:01:02.248537Z","shell.execute_reply":"2025-04-21T05:01:02.665961Z"}},"outputs":[{"name":"stdout","text":"Embeddings shape: (510, 384)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n/tmp/ipykernel_31/543742224.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  embedding_df[f'dim_{i}'] = contract_embeddings[:, i]\n","output_type":"stream"},{"name":"stdout","text":"Embeddings saved to /kaggle/working/contract_embeddings.csv\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# function to store it in the database of pine\n! pip install pinecone-client","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:01:31.224892Z","iopub.execute_input":"2025-04-21T05:01:31.225203Z","iopub.status.idle":"2025-04-21T05:01:34.858690Z","shell.execute_reply.started":"2025-04-21T05:01:31.225182Z","shell.execute_reply":"2025-04-21T05:01:34.857418Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting pinecone-client\n  Downloading pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2025.1.31)\nRequirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.9.0.post0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.13.1)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.17.0)\nDownloading pinecone_client-6.0.0-py3-none-any.whl (6.7 kB)\nInstalling collected packages: pinecone-client\nSuccessfully installed pinecone-client-6.0.0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Connect to the index\nindex = pc.Index(index_name)\n\n# Upsert embeddings into Pinecone\n# Prepare vectors with their IDs\nvectors = [\n    (str(i), embedding.tolist())\n    for i, embedding in enumerate(contract_embeddings)\n]\n\n# Upsert vectors in batches\nbatch_size = 100\nfor i in range(0, len(vectors), batch_size):\n    batch = vectors[i:i+batch_size]\n    index.upsert(batch)","metadata":{"id":"sYphd3xPEdKl","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:01:41.283421Z","iopub.execute_input":"2025-04-21T05:01:41.283767Z","iopub.status.idle":"2025-04-21T05:01:43.096465Z","shell.execute_reply.started":"2025-04-21T05:01:41.283739Z","shell.execute_reply":"2025-04-21T05:01:43.095890Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# for tagging the part of speech and the context type\n# BM25 for sparse retrieval\ntokenized_corpus = [doc.split() for doc in contract_texts]\nbm25 = BM25Okapi(tokenized_corpus)\n\n# Function for POS tagging with focus on legal terms\ndef legal_pos_tagging(text):\n    # Use NLTK for POS tagging\n    tokens = word_tokenize(text)\n    tagged = nltk.pos_tag(tokens)\n\n    # Filter for relevant POS tags:\n    # NN, NNS, NNP, NNPS (nouns)\n    # JJ, JJR, JJS (adjectives - often used in legal qualifiers)\n    # VB, VBD, VBG, VBN, VBP, VBZ (verbs - for obligations/permissions)\n    # CD (cardinal numbers - important for dates, amounts)\n    # IN (prepositions - often indicate relationships)\n    relevant_tags = ['NN', 'NNS', 'NNP', 'NNPS', 'JJ', 'JJR', 'JJS',\n                    'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'CD', 'IN']\n\n    filtered_tagged = [(word, tag) for word, tag in tagged if tag in relevant_tags]\n\n    # Get legal entities with Spacy\n    doc = nlp(text)\n    entities = [(ent.text, ent.label_) for ent in doc.ents]\n\n    return {\n        'pos_tagged': filtered_tagged,\n        'entities': entities\n    }\n\n","metadata":{"id":"CBO06W6VEoYs","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:01:47.317400Z","iopub.execute_input":"2025-04-21T05:01:47.318107Z","iopub.status.idle":"2025-04-21T05:01:48.760423Z","shell.execute_reply.started":"2025-04-21T05:01:47.318073Z","shell.execute_reply":"2025-04-21T05:01:48.759457Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Additional legal keywords and phrases to identify\nlegal_keywords = [\n    \"indemnification\", \"termination\", \"liability\", \"warranty\", \"confidentiality\", \"intellectual property\", \"assignment\", \"governing law\", \"jurisdiction\", \"cooperation\", \"severability\", \"waiver\", \"amendment\", \"notice\", \"term\", \"payment\", \"obligations\", \"representations\", \"shall\", \"must\", \"may not\", \"party\", \"agreement\", \"contract\", \"rights\", \"Acknowledgment\", \"action\", \"Condition\"\n]\n\ndef identify_legal_clauses(text):\n    # Basic keyword search\n    found_keywords = []\n    for keyword in legal_keywords:\n        if keyword.lower() in text.lower():\n            found_keywords.append(keyword)\n\n    # Get POS tags and entities\n    nlp_results = legal_pos_tagging(text)\n\n    return {\n        'legal_keywords': found_keywords,\n        'pos_tagged': nlp_results['pos_tagged'],\n        'entities': nlp_results['entities']\n    }","metadata":{"id":"oSPT9S9WE4Dz","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:03:44.875603Z","iopub.execute_input":"2025-04-21T05:03:44.876162Z","iopub.status.idle":"2025-04-21T05:03:44.881757Z","shell.execute_reply.started":"2025-04-21T05:03:44.876136Z","shell.execute_reply":"2025-04-21T05:03:44.880825Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# for the hybrid search\ndef hybrid_search(query, top_k=3):\n    # STEP 1: BM25 on content\n    contract_items = list(contracts.items())  # [(filename, content), ...]\n    contents = [content for _, content in contract_items]\n    bm25_results = bm25.get_top_n(query.split(), contents, n=top_k)\n\n    # Map BM25 results back to filenames (keys)\n    bm25_keys = [filename for filename, content in contract_items if content in bm25_results]\n\n    # STEP 2: Vector search using Pinecone\n    query_embedding = embedding_model.encode([query], convert_to_numpy=True)[0]\n\n    # Perform Pinecone search\n    pinecone_results = index.query(\n        vector=query_embedding.tolist(),\n        top_k=top_k,\n        include_metadata=False  # Since metadata is not being used, we exclude it\n    )\n\n    # Extract document IDs (which represent the contract keys) from Pinecone results\n    pinecone_keys = [result['id'] for result in pinecone_results['matches']]\n\n    # Combine and deduplicate the results from BM25 and Pinecone\n    combined_keys = list(dict.fromkeys(bm25_keys + pinecone_keys))  # Deduplicate while maintaining order\n\n    return combined_keys[:top_k]\n","metadata":{"id":"B5wg_WgrE8gL","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:03:48.501992Z","iopub.execute_input":"2025-04-21T05:03:48.502313Z","iopub.status.idle":"2025-04-21T05:03:48.508262Z","shell.execute_reply.started":"2025-04-21T05:03:48.502292Z","shell.execute_reply":"2025-04-21T05:03:48.507465Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"id":"-HkbsjarFAgV","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:03:54.632334Z","iopub.execute_input":"2025-04-21T05:03:54.632880Z","iopub.status.idle":"2025-04-21T05:03:54.758515Z","shell.execute_reply.started":"2025-04-21T05:03:54.632817Z","shell.execute_reply":"2025-04-21T05:03:54.757790Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# loading the model for generating the answer\n# Load model and tokenizer\nmodel_name = \"mistralai/Mistral-7B-v0.1\"\n# model_name = \"microsoft/Phi-3-medium-128k-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n# When loading the tokenizer:\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token  # Set padding token to be the same as EOS token\nmodel = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\nprint(\"Model loaded successfully on GPU!\")","metadata":{"id":"hMzLkBR_FHiK","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:03:57.362027Z","iopub.execute_input":"2025-04-21T05:03:57.362675Z","iopub.status.idle":"2025-04-21T05:05:42.162431Z","shell.execute_reply.started":"2025-04-21T05:03:57.362642Z","shell.execute_reply":"2025-04-21T05:05:42.161762Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d33bff541bae4710a37cbd77826b3e96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15a986667a104565b2f88fbe87c0d8e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfb71c07eaad4fe9aa1d5f18c4ea03f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c854067cb544d0798342b26c4b2fc36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b31de410a68341d88963d21c389c6ca0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b274e77b85e47a3bbdd69d4ab800cf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5905f295f02b435ba45a023482cc72bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c22220fb1b2e47d5ab4b42f5ab091354"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d4c6db6e9484c1ab17cb454edf03ba0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99887cc30cd240dd919ff821b5c94b3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec110378ec7e4cf497471d5b8b064ace"}},"metadata":{}},{"name":"stdout","text":"Model loaded successfully on GPU!\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# for the question answering system\n# Classify question type\ndef classify_question_type(question):\n    multi_line_keywords = [\"explain\", \"details\", \"describe\", \"list\", \"elaborate\"]\n    return \"multi\" if any(word in question.lower() for word in multi_line_keywords) else \"single\"\n\ndef generate_response_with_cot(question, context):\n    \"\"\"\n    Generate a response to a legal contract question using Chain of Thought reasoning.\n\n    Args:\n        question: The legal question to answer\n        context: The relevant contract text\n\n    Returns:\n        A response with step-by-step reasoning\n    \"\"\"\n    if not context.strip():  # If no context is found\n        return \"No relevant information found in the provided contracts.\"\n\n    # Step 1: Analyze the question to identify its legal category\n    legal_analysis = identify_legal_clauses(question)\n    question_analysis = legal_pos_tagging(question)\n    key_terms = [word for word, tag in question_analysis['pos_tagged'] if tag.startswith('N') or tag.startswith('V')]\n\n    # Step 2: Identify the most relevant clauses in the context\n    legal_context_analysis = identify_legal_clauses(context[:5000])\n\n    # Step 3: Categorize the question type (factual, interpretive, etc.)\n    question_type = \"factual\"  # Default\n    interpretation_keywords = [\"interpret\", \"meaning\", \"understand\", \"implication\"]\n    consequence_keywords = [\"result\", \"consequence\", \"outcome\", \"effect\", \"affect\"]\n\n    if any(word in question.lower() for word in interpretation_keywords):\n        question_type = \"interpretive\"\n    elif any(word in question.lower() for word in consequence_keywords):\n        question_type = \"consequence-based\"\n\n    # Step 4: Craft a prompt that follows a chain of thought\n    prompt = f\"\"\"\n    Legal Question Analysis:\n    Question: {question}\n    Question Type: {question_type}\n    Key Legal Terms in Question: {', '.join(key_terms)}\n\n    Contract Context Analysis:\n    Relevant Legal Clauses: {', '.join(legal_context_analysis['legal_keywords'][:5]) if legal_context_analysis['legal_keywords'] else 'None'}\n    Key Entities: {', '.join([e[0] for e in legal_context_analysis['entities'][:3]]) if legal_context_analysis['entities'] else 'None'}\n\n    Thinking step by step to analyze this legal question:\n    1. First, I'll identify the specific contract provisions relevant to this question.\n    2. Next, I'll analyze how these provisions apply to the question asked.\n    3. Then, I'll consider any definitions or context that might affect interpretation.\n    4. Finally, I'll formulate a clear answer based on the contract language.\n\n    Contract Text Excerpt:\n    {context[:800]}\n\n    Step-by-Step Analysis:\n    \"\"\"\n\n    # Generate the chain of thought reasoning\n    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(\"cuda\")\n    reasoning_output = model.generate(**inputs, max_new_tokens=300)\n    reasoning = tokenizer.decode(reasoning_output[0], skip_special_tokens=True)\n\n    # Extract just the reasoning part\n    if \"Step-by-Step Analysis:\" in reasoning:\n        reasoning = reasoning.split(\"Step-by-Step Analysis:\")[1].strip()\n\n    # Now generate a concise final answer based on the reasoning\n    answer_prompt = f\"\"\"\n    After analyzing the legal contract:\n\n    {reasoning}\n\n    Concise Answer to the question \"{question}\":\n    \"\"\"\n\n    inputs = tokenizer(answer_prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(\"cuda\")\n    answer_output = model.generate(**inputs, max_new_tokens=150)\n    full_response = tokenizer.decode(answer_output[0], skip_special_tokens=True)\n\n    # Extract just the final answer\n    if \"Concise Answer\" in full_response:\n        answer = full_response.split(\"Concise Answer\")[1].strip()\n        if \":\" in answer:\n            answer = answer.split(\":\", 1)[1].strip()\n    else:\n        answer = full_response.split(\"\\n\")[-1].strip()\n\n    # Combine the reasoning and answer for a complete chain of thought response\n    cot_response = f\"\"\"\n    Step-by-Step Legal Analysis:\n    {reasoning}\n\n    Conclusion:\n    {answer}\n    \"\"\"\n\n    return cot_response.strip()","metadata":{"id":"C44XJpGVFNqF","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:07:55.092539Z","iopub.execute_input":"2025-04-21T05:07:55.093357Z","iopub.status.idle":"2025-04-21T05:07:55.104503Z","shell.execute_reply.started":"2025-04-21T05:07:55.093333Z","shell.execute_reply":"2025-04-21T05:07:55.103899Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# code for checking the rouge score.\n\ndef evaluate_response_quality(question, answer, context=None, reference=None):\n    \"\"\"\n    Evaluate the quality of a generated answer using ROUGE-1 and BERTScore,\n    focusing on context-answer relevance rather than question-answer lexical overlap.\n\n    Args:\n        question: The question asked\n        answer: The generated answer\n        context: The context used to generate the answer (optional)\n        reference: Reference answer for comparison (optional)\n\n    Returns:\n        Dictionary of evaluation metrics\n    \"\"\"\n    metrics = {}\n\n    # Initialize ROUGE scorer with rouge1 (unigram overlap)\n    rouge_scorer_instance = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n\n    # Context-Answer Relevance (if context is provided)\n    if context:\n        # For long contexts, extract the most relevant portions\n        # Based on sentence-level similarity to the question\n        sentences = [s.strip() for s in re.split(r'(?<=[.!?])\\s+', context) if s.strip()]\n\n        # Select the most relevant sentences by finding sentences containing key terms from the question\n        question_terms = set(word.lower() for word in re.findall(r'\\b\\w+\\b', question))\n        relevant_sentences = []\n\n        for sentence in sentences:\n            sentence_terms = set(word.lower() for word in re.findall(r'\\b\\w+\\b', sentence))\n            # Check if there's term overlap with the question\n            if question_terms.intersection(sentence_terms):\n                relevant_sentences.append(sentence)\n\n        # If we found relevant sentences, use them; otherwise use the first few sentences\n        if relevant_sentences and len(relevant_sentences) > 2:\n            relevant_context = \" \".join(relevant_sentences[:10])  # Limit to 10 sentences\n        else:\n            relevant_context = \" \".join(sentences[:10])  # Use first 10 sentences\n\n        # Measure ROUGE between context and answer (primary metric)\n        rouge1_ca = rouge_scorer_instance.score(relevant_context, answer)\n        metrics['rouge1_context_answer'] = rouge1_ca['rouge1'].fmeasure\n\n         # Reference Comparison (if a reference answer is provided)\n    if reference:\n        rouge1_ra = rouge_scorer_instance.score(reference, answer)\n        metrics['rouge1_reference_answer'] = rouge1_ra['rouge1'].fmeasure\n\n    # GEval metrics\n    try:\n        # GEval - General Evaluation - Fix: provide required parameters\n        evaluation_params = {\n          \"threshold\": 0.7,  # Default threshold for passing\n          \"model\": \"gpt-4\",  # You can change this based on your preference\n          \"criteria\": [  # Add specific criteria for evaluation\n              \"The answer is factually accurate based on the provided context\",\n              \"The answer directly addresses the question that was asked\",\n              \"The answer includes relevant information from the contract\"\n          ]\n        }\n        geval = GEval(name=\"general_evaluation\", evaluation_params=evaluation_params)\n\n        if context:\n            geval_score = geval.calculate_score(\n                question=question,\n                answer=answer,\n                context=relevant_context if 'relevant_context' in locals() else context[:5000]\n            )\n            metrics['geval_score'] = geval_score\n\n       # Contextual Relevancy - measures how relevant the answer is to the context\n        contextual_relevancy_metric = ContextualRelevancyMetric()\n        if context:\n            contextual_relevancy_score = contextual_relevancy_metric.calculate_score(\n                answer=answer,\n                context=relevant_context if 'relevant_context' in locals() else context[:5000]\n            )\n            metrics['contextual_relevancy_score'] = contextual_relevancy_score\n\n        # Prompt Alignment - measures how well the answer aligns with the question\n        prompt_alignment_metric = PromptAlignmentMetric()\n        prompt_alignment_score = prompt_alignment_metric.calculate_score(\n            question=question,\n            answer=answer\n        )\n        metrics['prompt_alignment_score'] = prompt_alignment_score\n\n        # Summarization metric - useful when evaluating summaries\n        if \"summarize\" in question.lower() or \"summary\" in question.lower():\n            summarization_metric = SummarizationMetric()\n            if context:\n                summarization_score = summarization_metric.calculate_score(\n                    answer=answer,\n                    context=relevant_context if 'relevant_context' in locals() else context[:5000]\n                )\n                metrics['summarization_score'] = summarization_score\n\n    except Exception as e:\n        print(f\"Error calculating GEval metrics: {e}\")\n        metrics['geval_error'] = str(e)\n\n    # Composite score based on available metrics\n    available_scores = []\n    if 'rouge1_context_answer' in metrics:\n        available_scores.append(metrics['rouge1_context_answer'])\n    if 'contextual_relevancy_score' in metrics:\n        available_scores.append(metrics['contextual_relevancy_score'])\n    if 'prompt_alignment_score' in metrics:\n        available_scores.append(metrics['prompt_alignment_score'])\n    if 'summarization_score' in metrics:\n        available_scores.append(metrics['summarization_score'])\n\n    if available_scores:\n        metrics['composite_score'] = sum(available_scores) / len(available_scores)\n\n    return metrics\n\ndef interpret_evaluation_scores(metrics):\n    \"\"\"\n    Interpret the evaluation metrics in human-readable terms,\n    emphasizing context-answer relevance over question-answer overlap.\n\n    Args:\n        metrics: Dictionary of evaluation metrics\n\n    Returns:\n        String with interpretations\n    \"\"\"\n    interpretations = []\n\n    # Interpret ROUGE-1 context-answer scores\n    if 'rouge1_context_answer' in metrics:\n        score = metrics['rouge1_context_answer']\n        if score >= 0.4:\n            interpretations.append(\"✓ EXCELLENT TERMINOLOGY MATCH: Answer uses key terminology from the relevant contract sections.\")\n        elif score >= 0.25:\n            interpretations.append(\"✓ GOOD TERMINOLOGY MATCH: Answer incorporates terminology from the relevant contract sections.\")\n        elif score >= 0.15:\n            interpretations.append(\"⚠ FAIR TERMINOLOGY MATCH: Answer uses some terminology from the contract context.\")\n        else:\n            interpretations.append(\"⚠ POOR TERMINOLOGY MATCH: Answer uses minimal terminology from the contract context.\")\n\n    # Interpret GEval metrics\n    if 'contextual_relevancy_score' in metrics:\n        score = metrics['contextual_relevancy_score']\n        if score >= 0.8:\n            interpretations.append(\"✓ HIGH CONTEXTUAL RELEVANCE: The answer is firmly grounded in the provided contract context.\")\n        elif score >= 0.6:\n            interpretations.append(\"✓ GOOD CONTEXTUAL RELEVANCE: The answer is generally aligned with the contract context.\")\n        else:\n            interpretations.append(\"⚠ LOW CONTEXTUAL RELEVANCE: The answer may not be sufficiently based on the contract context.\")\n\n    if 'prompt_alignment_score' in metrics:\n        score = metrics['prompt_alignment_score']\n        if score >= 0.8:\n            interpretations.append(\"✓ EXCELLENT QUESTION ALIGNMENT: The answer directly addresses what was asked.\")\n        elif score >= 0.6:\n            interpretations.append(\"✓ GOOD QUESTION ALIGNMENT: The answer generally addresses what was asked.\")\n        else:\n          interpretations.append(\"⚠ POOR QUESTION ALIGNMENT: The answer may not properly address the question.\")\n\n    if 'summarization_score' in metrics:\n        score = metrics['summarization_score']\n        if score >= 0.8:\n            interpretations.append(\"✓ EXCELLENT SUMMARY QUALITY: The summary captures key information comprehensively.\")\n        elif score >= 0.6:\n            interpretations.append(\"✓ GOOD SUMMARY QUALITY: The summary covers most important points.\")\n        else:\n            interpretations.append(\"⚠ INADEQUATE SUMMARY: The summary may miss important details or be inaccurate.\")\n\n    if 'geval_score' in metrics:\n        score = metrics['geval_score']\n        if score >= 0.8:\n            interpretations.append(\"✓ EXCELLENT OVERALL QUALITY: The response meets high standards of relevance and accuracy.\")\n        elif score >= 0.6:\n            interpretations.append(\"✓ GOOD OVERALL QUALITY: The response is generally relevant and accurate.\")\n        else:\n            interpretations.append(\"⚠ SUBOPTIMAL QUALITY: The response may have issues with relevance or accuracy.\")\n\n    # Interpret composite score if available\n    if 'composite_score' in metrics:\n        score = metrics['composite_score']\n        if score >= 0.7:\n            interpretations.append(\"\\n✓ OVERALL EXCELLENT QUALITY: The answer demonstrates high quality and relevance.\")\n        elif score >= 0.5:\n            interpretations.append(\"\\n✓ OVERALL GOOD QUALITY: The answer demonstrates good quality and relevance.\")\n        elif score >= 0.3:\n            interpretations.append(\"\\n⚠ OVERALL ACCEPTABLE QUALITY: The answer demonstrates acceptable but limited quality and relevance.\")\n        else:\n            interpretations.append(\"\\n⚠ OVERALL POOR QUALITY: The answer may lack quality and relevance.\")\n\n    # Add technical score details\n    scores = []\n    if 'rouge1_context_answer' in metrics:\n        scores.append(f\"ROUGE-1 Context-Answer: {metrics['rouge1_context_answer']:.3f}\")\n    if 'geval_score' in metrics:\n        scores.append(f\"GEval Score: {metrics['geval_score']:.3f}\")\n    if 'contextual_relevancy_score' in metrics:\n        scores.append(f\"Contextual Relevancy: {metrics['contextual_relevancy_score']:.3f}\")\n    if 'prompt_alignment_score' in metrics:\n        scores.append(f\"Prompt Alignment: {metrics['prompt_alignment_score']:.3f}\")\n    if 'summarization_score' in metrics:\n        scores.append(f\"Summarization Quality: {metrics['summarization_score']:.3f}\")\n    if 'composite_score' in metrics:\n        scores.append(f\"Composite Score: {metrics['composite_score']:.3f}\")\n\n    # Add scores at the end\n    technical_scores = \"\\nTechnical Scores: \" + \", \".join(scores)\n\n    return \"\\n\".join(interpretations), technical_scores","metadata":{"id":"_vQ-U1rKFwer","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:08:20.540386Z","iopub.execute_input":"2025-04-21T05:08:20.541150Z","iopub.status.idle":"2025-04-21T05:08:21.280722Z","shell.execute_reply.started":"2025-04-21T05:08:20.541124Z","shell.execute_reply":"2025-04-21T05:08:21.279976Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# answer with the evaluvation\n# Function to update the evaluation in your main answer_question_with_evaluation function\ndef answer_question_with_evaluation(question, custom_doc=None, return_details=True, include_scores=False):\n    \"\"\"\n    Answer legal questions and evaluate the quality of the response.\n\n    Args:\n        question: The legal question to answer\n        custom_doc: Optional custom document text\n        return_details: Whether to return evaluation details\n        include_scores: Whether to include technical scores in the output\n\n    Returns:\n        Dict with answer and evaluation metrics\n    \"\"\"\n    if custom_doc:\n        context = custom_doc\n        retrieved_docs = [\"Custom Document\"]\n    else:\n        retrieved_docs = hybrid_search(question)\n        if not retrieved_docs:\n            return {\n                'answer': \"No relevant documents found for the query.\",\n                'evaluation': None,\n                'retrieved_docs': []\n            }\n        context = \" \".join([contracts.get(doc, \"\") for doc in retrieved_docs])\n\n    # Generate answer using the enhanced CoT approach\n    answer = generate_response_with_cot(question, context)\n\n    # Evaluate the answer quality using metrics\n    evaluation = evaluate_response_quality(question, answer, context)\n\n    # Add interpretation of the scores\n    evaluation_summary, technical_scores = interpret_evaluation_scores(evaluation)\n\n    result = {\n        'answer': answer,\n        'evaluation': evaluation,\n        'evaluation_summary': evaluation_summary,\n        'technical_scores': technical_scores,\n        'retrieved_docs': retrieved_docs\n    }\n\n    if not return_details:\n        # Return a simplified version\n        output = f\"\"\"\n          Answer:\n          {answer}\n\n          Evaluation Summary:\n          {evaluation_summary}\n        \"\"\"\n\n        if include_scores:\n            output += f\"\\n{technical_scores}\"\n\n        return output\n\n    return result","metadata":{"id":"tkgcNyrqF_rI","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:08:30.319085Z","iopub.execute_input":"2025-04-21T05:08:30.319675Z","iopub.status.idle":"2025-04-21T05:08:30.325842Z","shell.execute_reply.started":"2025-04-21T05:08:30.319648Z","shell.execute_reply":"2025-04-21T05:08:30.324964Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# function for summarize the contract\n\ndef summarize_document(doc_text):\n    \"\"\"Generate a summary in bullet points with a limit of 100-200 words.\"\"\"\n    # First identify key legal components\n    legal_components = identify_legal_clauses(doc_text[:10000])  # Limit to first 10K chars\n\n    # Create a prompt that emphasizes the legal components\n    prompt = f\"\"\"\n    Summarize the following legal document in bullet points, focusing on these key legal terms: {', '.join(legal_components['legal_keywords'][:10])}\n\n    Document: {doc_text[:1000]}\n\n    Summary:\"\"\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True).to(\"cuda\")\n\n    # Generate summary\n    summary_ids = model.generate(**inputs, max_new_tokens=250)\n    summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n    # Extract just the summary part\n    if \"Summary:\" in summary_text:\n        summary_text = summary_text.split(\"Summary:\")[1].strip()\n\n    # Convert summary into bullet points if not already\n    if not summary_text.startswith(\"- \"):\n        bullet_points = summary_text.split(\". \")\n        formatted_summary = \"\\n\".join([f\"- {point.strip()}\" for point in bullet_points if point.strip()])\n    else:\n        formatted_summary = summary_text\n\n    # Limit to 100-200 words\n    words = formatted_summary.split()\n    if len(words) > 200:\n        formatted_summary = \" \".join(words[:200]) + \"...\"\n\n    return formatted_summary","metadata":{"id":"GnRUzEyxGGIg","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:09:54.616245Z","iopub.execute_input":"2025-04-21T05:09:54.617257Z","iopub.status.idle":"2025-04-21T05:09:54.625485Z","shell.execute_reply.started":"2025-04-21T05:09:54.617221Z","shell.execute_reply":"2025-04-21T05:09:54.624489Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# extract the text content from the pdf\ndef extract_text_from_pdf(pdf_file):\n    \"\"\"Extract text from an uploaded PDF file.\"\"\"\n    text = \"\"\n    reader = pypdf.PdfReader(pdf_file)\n    for page in reader.pages:\n        extracted_text = page.extract_text()\n        if extracted_text:\n            text += extracted_text + \"\\n\"\n    return text.strip() if text else \"Could not extract text from PDF.\"\n","metadata":{"id":"wyofutBzGN06","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:09:59.044290Z","iopub.execute_input":"2025-04-21T05:09:59.044915Z","iopub.status.idle":"2025-04-21T05:09:59.048996Z","shell.execute_reply.started":"2025-04-21T05:09:59.044891Z","shell.execute_reply":"2025-04-21T05:09:59.048342Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# this is for the gradio function\ndef process_input_with_evaluation(option, question, pdf_file, show_scores=False):\n    if option == \"Ask a question on stored contracts\":\n        result = answer_question_with_evaluation(question, include_scores=show_scores)\n        if isinstance(result, dict):\n            output = f\"\"\"\n            Answer:\n            {result['answer']}\n\n            Evaluation:\n            {result['evaluation_summary']}\n\n            Sources: {', '.join(result['retrieved_docs'])}\n            \"\"\"\n\n            if show_scores:\n                output += f\"\\n{result['technical_scores']}\"\n\n            return output\n        else:\n            return result\n\n    elif option == \"Upload a PDF and ask a question\":\n        if pdf_file is None:\n            return \"Please upload a PDF document.\"\n        doc_text = extract_text_from_pdf(pdf_file.name)\n        result = answer_question_with_evaluation(question, custom_doc=doc_text, include_scores=show_scores)\n        if isinstance(result, dict):\n            output = f\"\"\"\n            Answer:\n            {result['answer']}\n\n            Evaluation:\n            {result['evaluation_summary']}\n\n            Source: Custom Document\n            \"\"\"\n\n            if show_scores:\n                output += f\"\\n{result['technical_scores']}\"\n\n            return output\n        else:\n            return result\n\n    elif option == \"Upload a PDF and get a summary\":\n        if pdf_file is None:\n            return \"Please upload a PDF document.\"\n        doc_text = extract_text_from_pdf(pdf_file.name)\n        summary = summarize_document(doc_text)\n\n        # Evaluate summary quality by comparing to original document\n        evaluation = evaluate_response_quality(\"Summarize this legal document\", summary, doc_text)\n        evaluation_summary, technical_scores = interpret_evaluation_scores(evaluation)\n\n        output = f\"\"\"Summary:\n        {summary}\n\n        Evaluation:\n        {evaluation_summary}\n        \"\"\"\n\n        if show_scores:\n            output += f\"\\n{technical_scores}\"\n\n        return output","metadata":{"id":"ho-zr0tsGXnH","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:10:04.599795Z","iopub.execute_input":"2025-04-21T05:10:04.600607Z","iopub.status.idle":"2025-04-21T05:10:04.611634Z","shell.execute_reply.started":"2025-04-21T05:10:04.600572Z","shell.execute_reply":"2025-04-21T05:10:04.610615Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# the gradio working\n# Start the Gradio interface with evaluation\ndemo = update_gradio_with_evaluation()\ndemo.launch()","metadata":{"id":"M8-yIWPtGr9w"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# AGENTS SIDE.","metadata":{"id":"euQN7MSVHRxd"}},{"cell_type":"code","source":"# the header installation.\nimport os\nfrom typing import Annotated, List, Literal, Optional, Union\nfrom typing_extensions import TypedDict\n\nimport google.generativeai as genai\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import add_messages\nfrom langgraph.prebuilt import ToolNode, InjectedState\nfrom langchain_core.messages import AIMessage, HumanMessage, ToolMessage\nfrom langchain_core.tools import tool\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom typing import Dict\nfrom langchain.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnableSequence\nfrom langchain_core.tools import tool\nfrom langchain_community.llms import HuggingFacePipeline\nimport torch","metadata":{"id":"zm8LE9_cHLvm","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:13:32.640475Z","iopub.execute_input":"2025-04-21T05:13:32.640828Z","iopub.status.idle":"2025-04-21T05:13:33.709276Z","shell.execute_reply.started":"2025-04-21T05:13:32.640807Z","shell.execute_reply":"2025-04-21T05:13:33.708466Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# first part of the agents\n\n# Configure the generative AI client with the API key\ngenai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n\n# Define the state for the contract analysis agent\nclass ContractAnalysisState(TypedDict):\n    \"\"\"State representing the contract analysis conversation.\"\"\"\n    # The chat conversation history\n    messages: Annotated[list, add_messages]\n    # The documents retrieved for analysis\n    retrieved_documents: List[str]\n    # Extracted legal clauses from the documents\n    extracted_clauses: dict\n    # Analysis results\n    analysis_results: dict\n    # Flag indicating if the analysis is complete\n    finished: bool\n    # Temporary PDF file path\n    current_pdf: Optional[str]\n\n# System instruction for the contract analysis agent\nCONTRACT_AGENT_SYSINT = (\n    \"system\",  # indicates message is a system instruction\n    \"You are a Contract Analysis Agent, designed to help legal professionals analyze and understand complex contracts. \"\n    \"You can extract key information, identify important clauses, summarize sections, compare terms, \"\n    \"and flag potential issues or risks. You should always be precise and cautious in your legal analysis. \"\n    \"When handling legal documents, clearly indicate when something is your interpretation versus explicit contract language. \"\n    \"You have access to the following tools:\\n\"\n    \"- search_contracts: Find relevant contracts based on a query\\n\"\n    \"- extract_clauses: Extract specific clause types from contracts\\n\"\n    \"- summarize_contract: Generate a concise summary of a contract\\n\"\n    \"- analyze_risks: Identify potential risks or issues in a contract\\n\"\n    \"- compare_contracts: Compare multiple contracts or clauses\\n\"\n    \"- get_definitions: Extract defined terms from a contract\\n\"\n    \"- check_compliance: Check if a contract complies with specified requirements\"\n    \"- answer_question_with_evaluation: Answer questions about stored contracts with quality evaluation\\n\"\n    \"- process_uploaded_pdf_question: Answer questions about an uploaded PDF contract\\n\"\n    \"- summarize_uploaded_pdf: Generate a summary of an uploaded PDF contract\"\n)\n\n# Welcome message\nWELCOME_MSG = \"Welcome to the Contract Analysis System. I can help you analyze contracts, extract important information, identify risks, and more. How can I assist you today?\"\n\n# Create LLM instance\n# Initialize the language model\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-1.5-flash\",\n    google_api_key=\"AIzaSyBKvar15joF09vV1jIeYggEiDFMGa4LYpw\"  # Replace with your key\n)\n","metadata":{"id":"vF2UAZpOHdWs","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:13:52.801158Z","iopub.execute_input":"2025-04-21T05:13:52.801526Z","iopub.status.idle":"2025-04-21T05:13:52.858653Z","shell.execute_reply.started":"2025-04-21T05:13:52.801492Z","shell.execute_reply":"2025-04-21T05:13:52.858136Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"**For getting the definitions**","metadata":{"id":"s_7AvwHcH-ST"}},{"cell_type":"code","source":"import re\n\ndef extract_definitions(contract_text: str, max_definitions: int = 20) -> str:\n    \"\"\"Extract explicitly defined terms from contract text with their definitions.\"\"\"\n    \n    # Look for \"Term\" means/shall mean/shall have the meaning of/etc.\n    pattern = r'[\"\\']([^\"\\']+)[\"\\']\\s+(?:shall\\s+)?(?:have\\s+the\\s+meaning\\s+of|have\\s+the\\s+meaning\\s+set\\s+forth\\s+in|means?|refers\\s+to)\\s+(.*?)(?:\\.|\\n|;|\\r)'\n    \n    matches = re.findall(pattern, contract_text, flags=re.IGNORECASE)\n    \n    # Deduplicate and keep first N\n    seen = set()\n    definitions = []\n    for term, definition in matches:\n        if term.lower() not in seen:\n            seen.add(term.lower())\n            definitions.append((term.strip(), definition.strip()))\n        if len(definitions) >= max_definitions:\n            break\n\n    if not definitions:\n        return \"No definitions found.\"\n\n    # Format result\n    result = \"Extracted Definitions:\\n\\n\"\n    for term, definition in definitions:\n        result += f\"Term: {term}\\nDefinition: {definition}\\n\\n\"\n\n    return result\n","metadata":{"id":"498CjpSIKuRr","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:14:47.877542Z","iopub.execute_input":"2025-04-21T05:14:47.877818Z","iopub.status.idle":"2025-04-21T05:14:47.883635Z","shell.execute_reply.started":"2025-04-21T05:14:47.877800Z","shell.execute_reply":"2025-04-21T05:14:47.882687Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# # for the defefinition\n\n# from langchain_core.prompts import PromptTemplate\n# from langchain_core.runnables import RunnableSequence\n# from langchain_core.language_models import BaseLanguageModel\n\n# # Assume `model` is already initialized as your language model (e.g., ChatOpenAI, ChatGoogle, etc.)\n\n# # Prompt template for extracting defined terms, focused on definitions only\n# definition_prompt = PromptTemplate.from_template(\"\"\"\n# You are a legal assistant. Extract only the definitions of the terms explicitly defined in the following contract text.\n\n# Contract:\n# {contract_text}\n\n# Return only the definitions, in this format:\n# [\n#   \"Definition of term 1\",\n#   \"Definition of term 2\",\n#   ...\n# ]\n\n# Only include definitions that are clearly and explicitly defined. Do not return any terms or additional text.\n# Do not make up any definitions.\n# \"\"\")\n\n# # Create the chain\n# definition_chain: RunnableSequence = definition_prompt | model\n\n# # Function to run the definition extraction chain\n# def extract_definitions(contract_text: str, max_chars: int = 8000) -> str:\n#     \"\"\"\n#     Extracts only the definitions of explicitly defined terms from a legal contract.\n\n#     Args:\n#         contract_text (str): The full contract text.\n#         max_chars (int): Maximum number of characters to consider for LLM context window.\n\n#     Returns:\n#         str: A list of definitions, formatted as a JSON string.\n#     \"\"\"\n#     # Truncate the contract text to fit within the context window\n#     truncated_text = contract_text[:1000]\n\n#     # Get the raw response from the chain\n#     raw_response = definition_chain.invoke({\"contract_text\": truncated_text})\n\n#     # Clean up and return only the definitions as a JSON string\n#     return raw_response.strip()\n","metadata":{"id":"dJTbBL2tHpdr"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**For the contract compare function**","metadata":{"id":"jfRt70b1ILmR"}},{"cell_type":"code","source":"from typing import List\nfrom numpy import dot\nfrom numpy.linalg import norm\nimport numpy as np\nimport pinecone\n\ndef cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n    \"\"\"Compute cosine similarity between two embedding vectors.\"\"\"\n    v1 = np.array(vec1)\n    v2 = np.array(vec2)\n    return float(dot(v1, v2) / (norm(v1) * norm(v2)))\n\ndef compare_contract_embeddings(contract_ids: List[str]) -> str:\n    \"\"\"\n    Compare contract embeddings using cosine similarity.\n    Returns similarity scores between each pair of contracts.\n    \"\"\"\n    comparison_result = \"\"\n    for i in range(len(contract_ids)):\n        for j in range(i + 1, len(contract_ids)):\n            id1 = contract_ids[i]\n            id2 = contract_ids[j]\n            vec1 = contract[id1]\n            vec2 = contract[id2]\n\n            if vec1 is None or len(vec1) == 0 or vec2 is None or len(vec2) == 0:\n                comparison_result += f\"\\n❌ Missing embedding for {id1 if vec1 is None or len(vec1) == 0 else id2}\\n\"\n                continue\n\n            similarity = cosine_similarity(vec1, vec2)\n            comparison_result += f\"🔍 Similarity between {id1} and {id2}: {similarity:.4f}\\n\"\n    return comparison_result\n","metadata":{"id":"dbmeHVt0IKIz","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:14:53.463010Z","iopub.execute_input":"2025-04-21T05:14:53.463799Z","iopub.status.idle":"2025-04-21T05:14:53.470771Z","shell.execute_reply.started":"2025-04-21T05:14:53.463772Z","shell.execute_reply":"2025-04-21T05:14:53.470116Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"**For the complaince check**","metadata":{"id":"6Ho7ID2cIXTi"}},{"cell_type":"code","source":"# check compliance\nfrom transformers import pipeline\n\ncompliance_pipeline = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n\ndef run_compliance_model(contract_text: str, requirements: str) -> str:\n    prompt = (\n        f\"Does the following contract comply with these requirements?\\n\\n\"\n        f\"Requirements:\\n{requirements}\\n\\nContract:\\n{contract_text[:2000]}\\n\\n\"\n        \"Answer YES or NO and explain why.\"\n    )\n    output = compliance_pipeline(prompt, max_new_tokens=150, do_sample=True)[0]['generated_text']\n    return output\n\n","metadata":{"id":"SF7PxrRaIfWg","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:47:44.098221Z","iopub.execute_input":"2025-04-20T12:47:44.098488Z","iopub.status.idle":"2025-04-20T12:48:01.084078Z","shell.execute_reply.started":"2025-04-20T12:47:44.098466Z","shell.execute_reply":"2025-04-20T12:48:01.083444Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58dfcf7021db4ad6b2039cbc6fe7cefd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1392eeb4011d497fafe8711a2ef58e54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9accfeaa79fe4bd9ae4929d46bd944f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29bb0509d7ac44bcb99b78532b3bb606"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235f356d9d884f3590d474ca9297a0ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc0f1eb876cd4443a7430fa9cb26b03a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4fdabd23ac4404688971639bc61620c"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# after the lora training\nfrom transformers import pipeline\n\n# Load your fine-tuned LegalBERT classification model\ncompliance_pipeline = pipeline(\n    \"text-classification\",\n    model=\"/kaggle/input/legalp/tensorflow2/default/1/legal_bert\",\n    tokenizer=\"bert-base-uncased\",\n    return_all_scores=False  # Set to True if you want probabilities for all classes\n)\n\ndef run_compliance_model(contract_text: str, requirements: str) -> str:\n    prompt = (\n        f\"Does the following contract comply with these requirements?\\n\\n\"\n        f\"Requirements:\\n{requirements}\\n\\nContract:\\n{contract_text[:2000]}\"\n    )\n\n    result = compliance_pipeline(prompt)[0]\n    label = result[\"label\"]\n    score = result[\"score\"]\n\n    label_map = {0: \"YES\", 1: \"MAYBE\", 2: \"NO\"}\n    label_id = int(result[\"label\"].split(\"_\")[-1])  # for label like 'LABEL_2'\n    return f\"Prediction: {label_map[label_id]} (confidence: {round(score * 100, 2)}%)\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:25:35.922128Z","iopub.execute_input":"2025-04-21T05:25:35.923059Z","iopub.status.idle":"2025-04-21T05:25:41.508354Z","shell.execute_reply.started":"2025-04-21T05:25:35.923024Z","shell.execute_reply":"2025-04-21T05:25:41.507469Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1f0dc5e372d47848fc4774753aec387"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e975616da7941ed89edf92d3e45afb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf2a6c5a61d1420eb4bea54db78c3e80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8349f7dabc4b8ba932ab8ff567f8d8"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"**Function for the risk analysis.**","metadata":{"id":"4oNorbNrImnn"}},{"cell_type":"code","source":"def perform_risk_analysis(contract_text: str) -> str:\n    \"\"\"Performs contract risk analysis using Gemini model via llm.invoke().\"\"\"\n\n    # Construct the prompt\n    prompt = f\"\"\"\nYou are a legal contracts expert. Review the following contract and identify any potential legal risks or red flags.\n\nContract excerpt:\n\\\"\\\"\\\"{contract_text[:2000]}\\\"\\\"\\\"\n\nIdentify and list:\n1. Missing or weak clauses\n2. Ambiguous or vague language\n3. Unfavorable or one-sided terms\n4. Potential compliance or regulatory issues\n\nFor each issue, provide:\n- A short title\n- A brief explanation of why it's a risk\n- A severity rating (Low, Medium, High)\n\nReturn the result in this format:\n\nRisk 1:\nTitle: ...\nDescription: ...\nSeverity: ...\n\nRisk 2:\n...\n\"\"\"\n\n    # Invoke Gemini model\n    response = llm.invoke(prompt)\n\n    # Clean and return output\n    return response.content.strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:25:57.841437Z","iopub.execute_input":"2025-04-21T05:25:57.841766Z","iopub.status.idle":"2025-04-21T05:25:57.846684Z","shell.execute_reply.started":"2025-04-21T05:25:57.841745Z","shell.execute_reply":"2025-04-21T05:25:57.845910Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# import torch\n\n# def perform_risk_analysis(contract_text: str) -> str:\n#     print(\"hi\")\n#     \"\"\"Performs LLM-based legal risk analysis on contract text.\"\"\"\n\n#     # Prompt engineering: guide the LLM to find risks\n#     prompt = f\"\"\"\n#     Analyze the following contract for potential legal risks and issues:\n\n#     {contract_text[:2000]}...\n\n#     Please identify:\n#     1. Missing or weak clauses\n#     2. Ambiguous language\n#     3. Unfavorable terms\n#     4. Compliance issues\n#     5. Each risk's severity (Low, Medium, High)\n\n#     Format your response as a list of risks with descriptions and severity levels.\n#     \"\"\"\n\n#     # Tokenize input prompt\n#     inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(\"cuda\")\n\n#     # Generate output using the LLM\n#     output = model.generate(**inputs, max_new_tokens=300)\n#     decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n\n#     # Post-process (remove prompt echoes if needed)\n#     if \"Format your response\" in decoded_output:\n#         decoded_output = decoded_output.split(\"Format your response\")[-1].strip()\n\n#     return decoded_output\n","metadata":{"id":"ClXOSaSqMGv2","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:03:09.049879Z","iopub.execute_input":"2025-04-20T13:03:09.050149Z","iopub.status.idle":"2025-04-20T13:03:09.055510Z","shell.execute_reply.started":"2025-04-20T13:03:09.050129Z","shell.execute_reply":"2025-04-20T13:03:09.054965Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"analyze_risks(\"2ThemartComInc_19990826_10-12G_EX-10.10_6700288_EX-10.10_Co-Branding Agreement_ Agency Agreement.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T13:22:24.992839Z","iopub.execute_input":"2025-04-20T13:22:24.993110Z","iopub.status.idle":"2025-04-20T13:22:29.773253Z","shell.execute_reply.started":"2025-04-20T13:22:24.993083Z","shell.execute_reply":"2025-04-20T13:22:29.772689Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"'Risk 1:\\nTitle: Missing Term of Agreement Duration\\nDescription: The agreement lacks a defined term or termination clause.  This leaves the agreement potentially open-ended, creating uncertainty for both parties and potential disputes regarding its continuation or termination.  One party might want to end the relationship while the other doesn\\'t, leading to costly litigation.\\nSeverity: High\\n\\nRisk 2:\\nTitle: Vague Definition of \"Marks\"\\nDescription: The definition of \"Marks\" is too broad (\"all domain names, trademarks and logos designated by a party for the other party\"). It lacks specificity about which marks are included and doesn\\'t address potential conflicts or licensing issues.  This could lead to disputes over usage rights and potential infringement claims.\\nSeverity: Medium\\n\\nRisk 3:\\nTitle: Unclear Ownership and Liability for Content\\nDescription: While the agreement defines \"Content,\" it doesn\\'t clearly delineate ownership rights or liability for inaccuracies, infringements, or defamatory content within the i-Escrow Content or 2TheMart Content. This ambiguity could expose one or both parties to legal action.\\nSeverity: Medium\\n\\nRisk 4:\\nTitle: Undefined Intellectual Property Rights\\nDescription: The agreement doesn\\'t explicitly address ownership or licensing of intellectual property created as a result of the co-branding arrangement. This is crucial, especially for any new content created specifically for the Co-Branded Site.  Without clear ownership definitions, disputes are likely.\\nSeverity: Medium\\n\\nRisk 5:\\nTitle: Ambiguous Launch Date Definition\\nDescription: The definition of \"LAUNCH DATE\" is vague.  \"Pointed to in all references\" and \"publicly deployed (post-beta)\" are subjective and lack concrete metrics for determining when the launch date is actually reached. This could lead to disagreements on when obligations begin.\\nSeverity: Medium\\n\\nRisk 6:\\nTitle: Missing Indemnification Clause\\nDescription: A critical missing element is an indemnification clause. This clause would allocate responsibility for damages or losses arising from the agreement.  Without it, both parties bear significant risk.\\nSeverity: High\\n\\nRisk 7:\\nTitle: Missing Governing Law and Dispute Resolution Clause\\nDescription: The contract lacks a clause specifying the governing law (which state\\'s laws will apply) and a dispute resolution mechanism (e.g., arbitration, litigation). This creates uncertainty regarding the jurisdiction and process for resolving any disputes.\\nSeverity: Medium\\n\\nRisk 8:\\nTitle:  Outdated Agreement - Potential for Inconsistent Practices\\nDescription: The agreement is dated June 21, 1999.  Legal and technological landscapes have changed significantly since then. The agreement may not reflect current best practices, legal requirements (e.g., data privacy laws like CCPA/GDPR), or industry standards, leading to non-compliance risks.\\nSeverity: High\\n\\nRisk 9:\\nTitle:  Lack of Detailed Escrow Service Description\\nDescription: While \"ESCROW SERVICES\" is defined, the description is very brief.  Crucial details about liability limitations, insurance requirements, dispute resolution within the escrow process itself are missing.  This leaves both parties vulnerable to unexpected liability.\\nSeverity: Medium\\n\\n\\nRisk 10:\\nTitle:  Information Transfer Mechanism Risks\\nDescription: The \"INFORMATION TRANSFER MECHANISM\" is mentioned but not detailed.  Security and liability for data breaches during the transfer of information between 2TheMart and i-Escrow are not addressed. This could result in significant legal and financial repercussions.\\nSeverity: Medium'"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"# # risk analysis\n# from langchain.schema import AIMessage\n\n# # Assume `contracts` is a dictionary {contract_id: contract_text}\n# # Assume `llm` is your language model instance with an `invoke` method\n\n# def perform_risk_analysis(contract_text: str) -> str:\n#     \"\"\"Perform risk analysis on the given contract text using the LLM.\"\"\"\n#     prompt = (\n#         \"You are a legal expert. Carefully analyze the following contract and identify any potential \"\n#         \"legal risks, compliance issues, or red flags. Be concise and provide bullet points:\\n\\n\"\n#         f\"{contract_text[:2000]}...\"  # Truncate to fit model context window\n#     )\n#     response = llm.invoke([AIMessage(content=prompt)])\n#     return response.content if hasattr(response, \"content\") else str(response)","metadata":{"id":"bN0impJUIgYb"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Helper function**","metadata":{"id":"FeYTt73tIw9X"}},{"cell_type":"code","source":"# Helper functions for PDF processing\ndef extract_text_from_pdf(pdf_path: str) -> str:\n    \"\"\"Extract text from an uploaded PDF file.\"\"\"\n    text = \"\"\n    reader = pypdf.PdfReader(pdf_path)\n    for page in reader.pages:\n        extracted_text = page.extract_text()\n        if extracted_text:\n            text += extracted_text + \"\\n\"\n    return text.strip() if text else \"Could not extract text from PDF.\"","metadata":{"id":"cHFHJkzOItsr","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:26:27.579620Z","iopub.execute_input":"2025-04-21T05:26:27.579919Z","iopub.status.idle":"2025-04-21T05:26:27.584650Z","shell.execute_reply.started":"2025-04-21T05:26:27.579897Z","shell.execute_reply":"2025-04-21T05:26:27.583846Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":" def generate_response(question, context):\n        if not context.strip():\n            return \"No relevant information found in the provided contracts.\"\n\n        prompt = f\"Legal Context: {context[:1000]}\\n\\nQuestion: {question}\\nAnswer:\"\n        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(\"cuda\")\n        output = model.generate(**inputs, max_new_tokens=150)\n        response = tokenizer.decode(output[0], skip_special_tokens=True)\n\n        if \"Answer:\" in response:\n            response = response.split(\"Answer:\")[1].strip()\n\n        return response.split(\"\\n\")[0].strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:26:31.216737Z","iopub.execute_input":"2025-04-21T05:26:31.217044Z","iopub.status.idle":"2025-04-21T05:26:31.222210Z","shell.execute_reply.started":"2025-04-21T05:26:31.217021Z","shell.execute_reply":"2025-04-21T05:26:31.221655Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def answer_question_from_contract(question: str) -> str:\n    \"\"\"\n    Retrieves relevant contracts using hybrid search, combines their content,\n    and generates a response using a generative model.\n    \"\"\"\n    # Step 1: Retrieve relevant contracts\n    relevant_contracts = hybrid_search(question)  # This should return a list of contract dicts or strings\n\n    # Step 2: Extract and join their content\n    if isinstance(relevant_contracts[0], dict):\n        contents = [contract.get(\"content\", \"\") for contract in relevant_contracts]\n    else:\n        contents = relevant_contracts  # Already a list of strings\n\n    combined_context = \"\\n\\n\".join(contents)\n\n    # Step 3: Generate a response based on question and context\n    response = generate_response(question, combined_context)\n\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:26:34.923668Z","iopub.execute_input":"2025-04-21T05:26:34.923956Z","iopub.status.idle":"2025-04-21T05:26:34.929035Z","shell.execute_reply.started":"2025-04-21T05:26:34.923937Z","shell.execute_reply":"2025-04-21T05:26:34.928424Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"**Tools**","metadata":{"id":"sIS4tZtZI2Rh"}},{"cell_type":"code","source":"# Define the tools\n@tool\ndef search_contracts(query: str) -> str:\n    \"\"\"Search for relevant contracts or contract sections based on the query.\"\"\"\n    results = hybrid_search(query, top_k=5)  # Implement hybrid_search elsewhere\n    print(\"search_contract\")\n    response = \"Found the following relevant contracts:\\n\"\n    for i, doc_name in enumerate(results):\n        response += f\"{i+1}. {doc_name}\\n\"\n    return response\n\n@tool\ndef extract_clauses(contract_id: str, clause_type: str = None) -> str:\n    \"\"\"Extract specific types of clauses from a contract.\"\"\"\n    if contract_id in contracts:\n        contract_text = contracts[contract_id]\n    else:\n        return f\"Contract {contract_id} not found in the database.\"\n\n    legal_analysis = identify_legal_clauses(contract_text)  # Implement identify_legal_clauses elsewhere\n    if clause_type:\n        for keyword in legal_analysis['legal_keywords']:\n            if clause_type.lower() == keyword.lower():\n                keyword_pos = contract_text.lower().find(keyword.lower())\n                if keyword_pos >= 0:\n                    start = max(0, keyword_pos - 200)\n                    end = min(len(contract_text), keyword_pos + 400)\n                    clause_extract = contract_text[start:end]\n                    return f\"Extracted '{keyword}' clause:\\n\\n{clause_extract}\"\n        return f\"Could not locate the specific text for '{clause_type}' clause.\"\n    return f\"Identified clauses: {', '.join(legal_analysis['legal_keywords'])}\"\n\n@tool\ndef summarize_contract(contract_id: str) -> str:\n    \"\"\"Generate a concise summary of a contract.\"\"\"\n    if contract_id in contracts:\n        contract_text = contract[contract_id]\n        return summarize_document(contract_text)  # Implement summarize_document elsewhere\n    return f\"Contract {contract_id} not found in the database.\"\n\n@tool\ndef analyze_risks(contract_id: str) -> str:\n    \"\"\"Identify potential risks or issues in a contract.\"\"\"\n    if contract_id in contracts:\n        contract_text = contracts[contract_id]\n        return perform_risk_analysis(contract_text)\n    return f\"Contract {contract_id} not found in the database.\"\n\n# def analyze_risks(contract_id: str) -> str:\n#     \"\"\"Identify potential risks or issues in a contract.\"\"\"\n#     if contract_id in contracts:\n#         contract_text = contracts[contract_id]\n#         return perform_risk_analysis(contract_text)\n#     return f\"Contract {contract_id} not found in the database.\"\n\n#\n@tool\ndef compare_contracts(contract_ids: List[str]) -> str:\n    \"\"\"Compare multiple contracts using embedding similarity (cosine).\"\"\"\n    if len(contract_ids) < 2:\n        return \"At least two contracts are required for comparison.\"\n\n    return compare_contract_embeddings(contract_ids)\n\n@tool\ndef get_definitions(contract_id: str) -> str:\n    \"\"\"Extract defined terms from a contract.\"\"\"\n    if contract_id in contracts:\n        contract_text = contracts[contract_id]\n        return extract_definitions(contract_text)\n    return f\"Contract {contract_id} not found in the database.\"\n# def get_definitions(contract_id: str) -> str:\n#     \"\"\"Extract defined terms from a contract.\"\"\"\n#     if contract_id in contracts:\n#         contract_text = contracts[contract_id]\n#         return extract_definitions(contract_text)  # Implement extract_definitions elsewhere\n#     return f\"Contract {contract_id} not found in the database.\"\n\n\n@tool\ndef check_compliance(contract_id: str, requirements: str) -> str:\n    \"\"\"Check if a contract complies with specified requirements.\"\"\"\n    if contract_id in contracts:\n        contract_text = contracts[contract_id]\n        return run_compliance_model(contract_text, requirements)\n    return f\"Contract '{contract_id}' not found in the database.\"\n\n# New evaluation and PDF processing tools\n@tool\ndef answer_question(question: str) -> str:\n    \"\"\"Answer a question about stored contracts with quality evaluation metrics.\"\"\"\n\n    result = answer_question_from_contract(question)\n    return result\n\n@tool\ndef process_uploaded_pdf_question(pdf_path: str, question: str) -> str:\n    \"\"\"Answer a question about an uploaded PDF contract with evaluation.\"\"\"\n    doc_text = extract_text_from_pdf(pdf_path)\n    result = generate_response(question, doc_text)\n    return result\n\n@tool\ndef summarize_uploaded_pdf(pdf_path: str) -> dict:\n    \"\"\"Generate a summary of an uploaded PDF contract with evaluation.\"\"\"\n    doc_text = extract_text_from_pdf(pdf_path)\n    summary = summarize_document(doc_text)\n\n    # # Evaluate summary quality\n    # evaluation = {\n    #     \"summary_quality\": \"The summary captures all key points accurately.\",\n    #     \"technical_scores\": {\n    #         \"coverage\": 0.94,\n    #         \"conciseness\": 0.89,\n    #         \"accuracy\": 0.93\n    #     } if include_scores else None\n    # }\n\n    # Evaluate summary quality by comparing to original document\n    output = f\"\"\"Summary:\n        {summary}\n        \"\"\"\n    return output","metadata":{"id":"A6YhRYkDI1rq","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:26:40.537809Z","iopub.execute_input":"2025-04-21T05:26:40.538100Z","iopub.status.idle":"2025-04-21T05:26:40.576133Z","shell.execute_reply.started":"2025-04-21T05:26:40.538081Z","shell.execute_reply":"2025-04-21T05:26:40.575469Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"answer_question(\"what is the name of cooper aggrment\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T15:36:40.893079Z","iopub.execute_input":"2025-04-20T15:36:40.893610Z","iopub.status.idle":"2025-04-20T15:36:52.035699Z","shell.execute_reply.started":"2025-04-20T15:36:40.893588Z","shell.execute_reply":"2025-04-20T15:36:52.034794Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f135a4b2bfd4f9b9b90b9105dd48c9f"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'Cooperative agreement is a contract between two or more parties to work together to achieve a common goal. The parties involved in the agreement may be government agencies, non-profit organizations, or private businesses. The agreement outlines the responsibilities of each party, the timeline for completion of the project, and the financial arrangements for the project.'"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"# second part of the agents\n\n# Set up contract analysis tools\ncontract_tools = [\n    search_contracts,\n    extract_clauses,\n    summarize_contract,\n    analyze_risks,\n    compare_contracts,\n    get_definitions,\n    check_compliance,\n    answer_question,\n    process_uploaded_pdf_question,\n    summarize_uploaded_pdf,\n]\n\n# Create automatic tool node\ntool_node = ToolNode(contract_tools)\n\n# Bind all tools to the LLM\nllm_with_tools = llm.bind_tools(contract_tools)","metadata":{"id":"18dwICjeI_jK","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:26:47.570180Z","iopub.execute_input":"2025-04-21T05:26:47.570506Z","iopub.status.idle":"2025-04-21T05:26:47.607273Z","shell.execute_reply.started":"2025-04-21T05:26:47.570482Z","shell.execute_reply":"2025-04-21T05:26:47.606716Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# third part of the contract\ndef contract_chatbot(state: ContractAnalysisState) -> ContractAnalysisState:\n    \"\"\"The contract analysis chatbot with tools.\"\"\"\n    defaults = {\n        \"retrieved_documents\": [],\n        \"extracted_clauses\": {},\n        \"analysis_results\": {},\n        \"finished\": False,\n        \"current_pdf\": None\n    }\n\n    if state[\"messages\"]:\n        # Only include system instruction at the start\n        messages = [CONTRACT_AGENT_SYSINT] if len(state[\"messages\"]) == 1 else []\n        messages += state[\"messages\"]\n        new_output = llm_with_tools.invoke(messages)\n    else:\n        new_output = AIMessage(content=WELCOME_MSG)\n\n    return defaults | state | {\"messages\": state[\"messages\"] + [new_output]}\n\ndef human_node(state: ContractAnalysisState) -> ContractAnalysisState:\n    \"\"\"Process human input and determine if we should exit.\"\"\"\n    # First display any AI messages\n    if state[\"messages\"]:\n        last_msg = state[\"messages\"][-1]\n        if isinstance(last_msg, AIMessage):\n            print(f\"AI: {last_msg.content}\")\n        elif isinstance(last_msg, ToolMessage):\n            print(f\"AI: [Tool execution completed]\")\n\n    # Then get human input\n    human_input = input(\"You: \")\n\n    if human_input.lower() in [\"exit\", \"quit\", \"q\", \"bye\"]:\n        return {\"messages\": state[\"messages\"], \"finished\": True}\n\n    return {\"messages\": state[\"messages\"] + [HumanMessage(content=human_input)]}\n\ndef maybe_exit_human_node(state: ContractAnalysisState) -> str:\n    \"\"\"Decide whether to continue the conversation or end it.\"\"\"\n    if state.get(\"finished\", False):\n        return END\n    else:\n        return \"chatbot\"\n\ndef maybe_route_to_tools(state: ContractAnalysisState) -> str:\n    \"\"\"Route between chat, tools, or end based on the current state.\"\"\"\n    if not (msgs := state.get(\"messages\", [])):\n        raise ValueError(f\"No messages found when parsing state: {state}\")\n\n    msg = msgs[-1]\n\n    if state.get(\"finished\", False):\n        return END\n\n    elif hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n        return \"tools\"\n\n    return \"human\"","metadata":{"id":"rRIMNCrUJGto","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:26:51.258191Z","iopub.execute_input":"2025-04-21T05:26:51.259087Z","iopub.status.idle":"2025-04-21T05:26:51.267166Z","shell.execute_reply.started":"2025-04-21T05:26:51.259033Z","shell.execute_reply":"2025-04-21T05:26:51.266557Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# building the graph\n# Create the state graph\ngraph_builder = StateGraph(ContractAnalysisState)\n\n# Add nodes\ngraph_builder.add_node(\"chatbot\", contract_chatbot)\ngraph_builder.add_node(\"human\", human_node)\ngraph_builder.add_node(\"tools\", tool_node)\n\n# Add edges\ngraph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\ngraph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\ngraph_builder.add_edge(\"tools\", \"chatbot\")\ngraph_builder.add_edge(START, \"chatbot\")\n\n# Compile the graph\ncontract_analysis_graph = graph_builder.compile()","metadata":{"id":"tlrBOu_wJMnA","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:26:56.427184Z","iopub.execute_input":"2025-04-21T05:26:56.427537Z","iopub.status.idle":"2025-04-21T05:26:56.433924Z","shell.execute_reply.started":"2025-04-21T05:26:56.427512Z","shell.execute_reply":"2025-04-21T05:26:56.433047Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# graph structure of the above\nfrom IPython.display import Image, display\nimport tempfile\n\nImage(contract_analysis_graph.get_graph().draw_mermaid_png())","metadata":{"id":"uQgUI9lDJQon","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:48:51.251701Z","iopub.execute_input":"2025-04-20T12:48:51.252359Z","iopub.status.idle":"2025-04-20T12:48:51.357742Z","shell.execute_reply.started":"2025-04-20T12:48:51.252336Z","shell.execute_reply":"2025-04-20T12:48:51.357111Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"image/png":"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\n","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"# last part running the agent\n# Run the agent\ndef run_contract_analysis_agent():\n    \"\"\"Start the contract analysis agent.\"\"\"\n    print(\"Starting Contract Analysis Agent...\")\n    print(\"Type 'exit', 'quit', or 'q' to end the conversation.\")\n    print(\"-\" * 50)\n\n    # Initialize with empty state\n    state = {\"messages\": []}\n\n    while True:\n        # Get AI response\n        state = contract_analysis_graph.invoke(state)\n\n        # Check if we should exit\n        if state.get(\"finished\", False):\n            print(\"AI: Thank you for using the Contract Analysis System. Goodbye!\")\n            break\n\n    return \"Contract analysis session completed.\"","metadata":{"id":"WngqePxqJWTZ","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:27:00.065972Z","iopub.execute_input":"2025-04-21T05:27:00.066894Z","iopub.status.idle":"2025-04-21T05:27:00.071672Z","shell.execute_reply.started":"2025-04-21T05:27:00.066865Z","shell.execute_reply":"2025-04-21T05:27:00.070905Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# run the agenst\n# Example usage\nif __name__ == \"__main__\":\n    run_contract_analysis_agent()","metadata":{"id":"129bHAnKJch_","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T05:27:03.558690Z","iopub.execute_input":"2025-04-21T05:27:03.559350Z","execution_failed":"2025-04-21T05:30:09.533Z"}},"outputs":[{"name":"stdout","text":"Starting Contract Analysis Agent...\nType 'exit', 'quit', or 'q' to end the conversation.\n--------------------------------------------------\nAI: Welcome to the Contract Analysis System. I can help you analyze contracts, extract important information, identify risks, and more. How can I assist you today?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  compliance check\n"},{"name":"stdout","text":"AI: Please provide me with the contract ID and the compliance requirements you'd like to check against.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  the contract id is \"/kaggle/input/atticus-open-contract-dataset-aok-beta/CUAD_v1/full_contract_txt/ACCELERATEDTECHNOLOGIESHOLDINGCORP_04_24_2003-EX-10.13-JOINT VENTURE AGREEMENT.txt\" and the requirement is does this follow payment term.\n"},{"name":"stdout","text":"AI: The provided contract ID is a file path, not a contract ID that the available tools can use.  The available functions require a contract ID that is internal to the system.  To check for payment terms, I need a valid contract ID from the system.  If you can provide a contract ID that the system recognizes, I can perform the compliance check.  Alternatively, if you can upload the contract as a PDF, I can try to process it using `process_uploaded_pdf_question`.  However, keep in mind that processing uploaded PDFs might not be as accurate as using system-internal contract IDs.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  the id is \"2ThemartComInc_19990826_10-12G_EX-10.10_6700288_EX-10.10_Co-Branding Agreement_ Agency Agreement.txt\"\n"},{"name":"stdout","text":"AI: Based on the provided contract ID (\"2ThemartComInc_19990826_10-12G_EX-10.10_6700288_EX-10.10_Co-Branding Agreement_ Agency Agreement.txt\") and the requirement \"payment term\", the system predicts with 96.65% confidence that the contract follows the payment terms.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  q\n"}],"execution_count":null}]}